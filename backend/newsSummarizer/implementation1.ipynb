{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luviGivqNhDB",
    "outputId": "522f2af1-67f6-408d-c6ae-8c1c2d087208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gkath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gkath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gkath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources if not already installed\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(\"Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dETvbCvhNyRv",
    "outputId": "40f5529a-f294-4c62-cec2-cef7145d65da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Delhi Police have sought information from Telegram regarding the \"Justice League India\" channel after a blast occurred near the CRPF School in Rohini, Delhi', ' The explosion damaged property but caused no injuries', ' Telegram has yet to respond, and investigations are ongoing, with no group claiming responsibility', '  The inquiry follows an explosion outside the CRPF School in Prashant Vihar, Rohini, where a post containing CCTV footage of the incident was shared on the channel', ' The police are also looking into other social media platforms', '  On Sunday, a mysterious explosion rocked the vicinity of the school, damaging the school wall, nearby shop windows, and a parked car', ' Fortunately, no injuries were reported', ' Police received a PCR call about the blast at approximately 7:47 AM and quickly responded to the scene', '  Upon arrival, officers discovered a damaged school wall emitting a foul odor, along with shattered windows and a damaged vehicle', ' Investigations are ongoing, exploring all possible angles', '    ']\n"
     ]
    }
   ],
   "source": [
    "# text = \"\"\" “Upon learning of the former president's request, we approached it through the lens of our core values: we open our doors to everyone,” McDonald's said in its message.\n",
    "# McDonald's said franchisees — who independently own and operate more than 95 per cent of US locations — have also invited Harris and her running mate Tim Walz for a visit.\n",
    "# Trump has sought to discredit, without evidence, Harris' claim about her job at the Golden Arches in the 1980s. McDonald's said that neither corporate nor franchisees have records for all positions going back to that time.\n",
    "# The Wall Street Journal earlier reported on the message. \"\"\"\n",
    "\n",
    "text='''Delhi Police have sought information from Telegram regarding the \"Justice League India\" channel after a blast occurred near the CRPF School in Rohini, Delhi. The explosion damaged property but caused no injuries. Telegram has yet to respond, and investigations are ongoing, with no group claiming responsibility.\n",
    "\n",
    "The inquiry follows an explosion outside the CRPF School in Prashant Vihar, Rohini, where a post containing CCTV footage of the incident was shared on the channel. The police are also looking into other social media platforms.\n",
    "\n",
    "On Sunday, a mysterious explosion rocked the vicinity of the school, damaging the school wall, nearby shop windows, and a parked car. Fortunately, no injuries were reported. Police received a PCR call about the blast at approximately 7:47 AM and quickly responded to the scene.\n",
    "\n",
    "Upon arrival, officers discovered a damaged school wall emitting a foul odor, along with shattered windows and a damaged vehicle. Investigations are ongoing, exploring all possible angles.\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "text = text.replace(\"\\n\",\" \")\n",
    "documentspreprocessedData = text.split(\".\")\n",
    "print(documentspreprocessedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EmqKl6GN66J"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YM8Xbu9PNq9a",
    "outputId": "3a03abda-77a2-4bb0-8799-4e186d9fbc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delhi police sought information telegram regarding justice league india channel blast occurred near crpf school rohini delhi', 'explosion damaged property caused injury', 'telegram yet respond investigation ongoing group claiming responsibility', 'inquiry follows explosion outside crpf school prashant vihar rohini post containing cctv footage incident shared channel', 'police also looking social medium platform', 'sunday mysterious explosion rocked vicinity school damaging school wall nearby shop window parked car', 'fortunately injury reported', 'police received pcr call blast approximately 747 quickly responded scene', 'upon arrival officer discovered damaged school wall emitting foul odor along shattered window damaged vehicle', 'investigation ongoing exploring possible angle', '']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text, use_stemming=False, use_lemmatization=True):\n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # 3. Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 4. Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 5. Stemming or Lemmatization\n",
    "    if use_stemming:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    elif use_lemmatization:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# preprocessed_text = preprocess_text(text)\n",
    "preprocessedData = [preprocess_text(sentence) for sentence in documentspreprocessedData]\n",
    "print(preprocessedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kckgLOjP3IO"
   },
   "source": [
    "TF-IDF Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ITyogwzeP0wm"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-GlXPLIN-Hw",
    "outputId": "abebef52-be50-4e70-b030-61ba5965d727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: police received pcr call blast approximately 747 quickly responded scene | Score: 1.5948868633716144\n",
      "Sentence: police also looking social medium platform | Score: 1.5892235621451007\n",
      "Sentence: fortunately injury reported | Score: 1.5695930562023703\n",
      "Sentence: telegram yet respond investigation ongoing group claiming responsibility | Score: 1.5526986766978637\n",
      "Sentence: investigation ongoing exploring possible angle | Score: 1.5425620489951595\n",
      "Sentence: upon arrival officer discovered damaged school wall emitting foul odor along shattered window damaged vehicle | Score: 1.5355380146179711\n",
      "Sentence: inquiry follows explosion outside crpf school prashant vihar rohini post containing cctv footage incident shared channel | Score: 1.5281335149410131\n",
      "Sentence: delhi police sought information telegram regarding justice league india channel blast occurred near crpf school rohini delhi | Score: 1.490820830298724\n",
      "Sentence: sunday mysterious explosion rocked vicinity school damaging school wall nearby shop window parked car | Score: 1.4664153164866691\n",
      "Sentence: explosion damaged property caused injury | Score: 1.4039326128831704\n",
      "Sentence:  | Score: 0\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(sentence):\n",
    "    words = sentence.split()\n",
    "    word_count = len(words)\n",
    "    tf_values = Counter(words)\n",
    "    for word in tf_values:\n",
    "        tf_values[word] = tf_values[word] / word_count\n",
    "    return tf_values\n",
    "\n",
    "def compute_idf(sentences):\n",
    "    num_sentences = len(sentences)\n",
    "    idf_values = {}\n",
    "    all_words = set(word for sentence in sentences for word in sentence.split())\n",
    "\n",
    "    for word in all_words:\n",
    "        containing_sentence_count = sum(1 for sentence in sentences if word in sentence.split())\n",
    "        idf_values[word] = math.log(num_sentences / (1 + containing_sentence_count))  # Adding 1 to avoid division by zero\n",
    "\n",
    "    return idf_values\n",
    "\n",
    "def compute_tfidf(sentences):\n",
    "    tf_list = [compute_tf(sentence) for sentence in sentences]\n",
    "\n",
    "    idf_values = compute_idf(sentences)\n",
    "\n",
    "    tfidf_list = []\n",
    "    for tf_values in tf_list:\n",
    "        tfidf = {}\n",
    "        for word, tf_value in tf_values.items():\n",
    "            tfidf[word] = tf_value * idf_values.get(word, 0)\n",
    "        tfidf_list.append(tfidf)\n",
    "\n",
    "    return tfidf_list\n",
    "\n",
    "def score_sentences(sentences, tfidf_list):\n",
    "    sentence_scores = []\n",
    "    for i, tfidf in enumerate(tfidf_list):\n",
    "        score = sum(tfidf.values())  # Sum up the TF-IDF values of all words in the sentence\n",
    "        sentence_scores.append((sentences[i], score))\n",
    "\n",
    "    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sentence_scores\n",
    "\n",
    "\n",
    "tfidf_list = compute_tfidf(preprocessedData)\n",
    "\n",
    "ranked_sentences = score_sentences(preprocessedData, tfidf_list)\n",
    "\n",
    "for sentence, score in ranked_sentences:\n",
    "    print(f\"Sentence: {sentence} | Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPHc_M33Q1vv"
   },
   "source": [
    "Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6SMiwziYRG2Z"
   },
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HYHLocl2QWbI"
   },
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "h_WDSlBNSjEv"
   },
   "outputs": [],
   "source": [
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "Dst8ZYuaRDUp",
    "outputId": "c6fadec6-7142-43a2-b0d2-5d0720cfc5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  police received pcr call blast approximately 747 quickly responded scene\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('police received pcr call blast approximately 747 quickly responded scene', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  police also looking social medium platform\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('police also looking social medium platform', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  fortunately injury reported\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('fortunately injury reported', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  telegram yet respond investigation ongoing group claiming responsibility\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('telegram yet respond investigation ongoing group claiming responsibility', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  investigation ongoing exploring possible angle\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('investigation ongoing exploring possible angle', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  upon arrival officer discovered damaged school wall emitting foul odor along shattered window damaged vehicle\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('upon arrival officer discovered damaged school wall emitting foul odor along shattered window damaged vehicle', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  inquiry follows explosion outside crpf school prashant vihar rohini post containing cctv footage incident shared channel\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('inquiry follows explosion outside crpf school prashant vihar rohini post containing cctv footage incident shared channel', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  delhi police sought information telegram regarding justice league india channel blast occurred near crpf school rohini delhi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('delhi police sought information telegram regarding justice league india channel blast occurred near crpf school rohini delhi', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  sunday mysterious explosion rocked vicinity school damaging school wall nearby shop window parked car\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('sunday mysterious explosion rocked vicinity school damaging school wall nearby shop window parked car', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  explosion damaged property caused injury\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('an explosion damaged property caused serious damage', 23)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     16\u001b[0m para_phrases \u001b[38;5;241m=\u001b[39m parrot\u001b[38;5;241m.\u001b[39maugment(input_phrase\u001b[38;5;241m=\u001b[39mphrase, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpara_phrase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpara_phrases\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpara_phrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara_phrase\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")\n",
    "\n",
    "# phrases = [\"trump sought discredit without evidence harris claim job golden arch 1980s\"]\n",
    "phrases = [text[0] for text in ranked_sentences]\n",
    "# print(phrases1)\n",
    "# phrases = [\"Can you recommend some upscale restaurants in Newyork?\",\n",
    "#            \"What are the famous places we should not miss in Russia?\"\n",
    "# ]\n",
    "# print(phrases)\n",
    "\n",
    "content = []\n",
    "for phrase in phrases:\n",
    "  print(\"-\"*100)\n",
    "  print(\"Input_phrase: \", phrase)\n",
    "  print(\"-\"*100)\n",
    "  para_phrases = parrot.augment(input_phrase=phrase, use_gpu=True)\n",
    "  for para_phrase in para_phrases:\n",
    "      print(para_phrase)\n",
    "      content.append(para_phrase[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police received pcr call blast approximately 747 quickly responded scene. police also looking social medium platform. fortunately injury reported. telegram yet respond investigation ongoing group claiming responsibility. investigation ongoing exploring possible angle. upon arrival officer discovered damaged school wall emitting foul odor along shattered window damaged vehicle. inquiry follows explosion outside crpf school prashant vihar rohini post containing cctv footage incident shared channel. delhi police sought information telegram regarding justice league india channel blast occurred near crpf school rohini delhi. sunday an explosion rocked a nearby school damaging a school wall nearby a shop window a parked car. explosion damaged property caused injury\n"
     ]
    }
   ],
   "source": [
    "# print(content)\n",
    "text = \". \".join(content)\n",
    "# print(content)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "FJnPsTqISFI5",
    "outputId": "3f15ee68-6c89-47b0-c9cb-91a3881ffeef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  trump sought discredit without evidence harris claim job golden arch 1980s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('trump sought discredit without evidence harris claim job golden arch 1980s', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  wall street journal earlier reported message\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('wall street journal earlier reported message', 0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input_phrase:  upon learning former president request approached lens core value open door everyone mcdonalds said message\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d961c7ae47d2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input_phrase: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   para_phrases = parrot.augment(input_phrase=phrase,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                \u001b[0mdiversity_ranker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"levenshtein\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parrot/parrot.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, input_phrase, use_gpu, diversity_ranker, do_diverse, max_return_phrases, max_length, adequacy_threshold, fluency_threshold)\u001b[0m\n\u001b[1;32m    110\u001b[0m               num_return_sequences=max_return_phrases)\n\u001b[1;32m    111\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         preds = self.model.generate(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2994\u001b[0;31m                 \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_warper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0madd_start_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOGITS_PROCESSOR_INPUTS_DOCSTRING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0msorted_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mcumulative_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")\n",
    "\n",
    "# phrases = [\"trump sought discredit without evidence harris claim job golden arch 1980s\"]\n",
    "phrases = [text[0] for text in ranked_sentences]\n",
    "\n",
    "# print(phrases)\n",
    "for phrase in phrases:\n",
    "  print(\"-\"*100)\n",
    "  print(\"Input_phrase: \", phrase)\n",
    "  print(\"-\"*100)\n",
    "  para_phrases = parrot.augment(input_phrase=phrase,\n",
    "                               use_gpu=False,\n",
    "                               diversity_ranker=\"levenshtein\",\n",
    "                               do_diverse=False,\n",
    "                               max_return_phrases = 10,\n",
    "                               max_length=32,\n",
    "                               adequacy_threshold = 0.99,\n",
    "                               fluency_threshold = 0.90)\n",
    "\n",
    "  for para_phrase in para_phrases:\n",
    "   print(para_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PTkB44pUaZ8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
